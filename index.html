<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo.">
  <meta name="keywords" content="Generalizable Gaussian Splatting, Multi-View Stereo, Neural Radiance Field, Novel View Synthesis">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MVSGaussian: Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo</title>
 
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>
  <link rel="shortcut icon" href="./static/images/faviconV3.png" type="image/png">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/own.min.css">
  <link rel="stylesheet" href="./static/css/custom.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link href="https://fonts.googleapis.com/css?family=Noto+Sans|Shantell+Sans" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/style.css">
  <link rel="stylesheet" href="./static/css/twentytwenty.css">
  <link rel="stylesheet" href="./static/css/twentytwenty_aios.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>

  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/jquery.event.move.js"></script>
  <script src="./static/js/jquery.twentytwenty.js"></script>
  <script src="./static/js/jquery.twentytwenty_aios.js"></script>
  <script>
    $(function () {
      $(".twentytwenty-container").twentytwenty();
      // $(".twentytwenty-container", "#results-carousel").twentytwenty({default_offset_pct: 0.5, ratio: 0.5});
    });
  </script>
  <script>$(function () { $(".twentytwenty_aios-container").twentytwenty_aios() });</script>
</head>
<body>



  <section class="hero">
    <div class="hero-body-background">
      <div class="hero-body-background-div"></div>
      <div style="text-align: center; z-index: 1; margin-top: 60px">
        <p class="word1 shakefont shadowtext" style="margin-right: -10px; color: #FFC5C5;font-family:PressStart2P">M</p>
        <p class="word2 shakefont shadowtext" style="margin-right: -10px; color: #ecd1aa;font-family:PressStart2P">V</p>
        <p class="word3 shakefont shadowtext" style="margin-right: -10px; color: #fe8e8e;font-family:PressStart2P">S</p>
        <p class="word4 shakefont shadowtext" style="margin-right: -10px; color: #98d4e6;font-family:PressStart2P">G</p>
        <p class="word5 shakefont shadowtext" style="margin-right: -10px; color: #9fd8ca;font-family:PressStart2P">a</p>
        <p class="word6 shakefont shadowtext" style="margin-right: -10px; color: #a4d6dd;font-family:PressStart2P">u</p>
        <p class="word7 shakefont shadowtext" style="margin-right: -10px; color: #dcdda4;font-family:PressStart2P">s</p>
        <p class="word8 shakefont shadowtext" style="margin-right: -10px; color: #23c29a;font-family:PressStart2P">s</p>
        <p class="word9 shakefont shadowtext" style="margin-right: -10px; color: #a6c5cd;font-family:PressStart2P">i</p>
        <p class="word10 shakefont shadowtext" style="margin-right: -10px; color: #c4b469;font-family:PressStart2P">a</p>
        <p class="word11 shakefont shadowtext" style="margin-right: -10px; color: #382e2f;font-family:PressStart2P">n</p>

        <p class="acmefont shadowtext high-font" style="color: #FFFFFF;">
          Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo
        </p>
        <p class="author-block sansfont shadowtext" style="color: #FFFFFF; font-size: 1.8em;">
                  ECCV 2024
        </p>
      </div>
      <!-- <div class="columns is-centered" style="z-index: 1; margin-top: -80px">
        <div class="column has-text-centered ">
            <div class="publication-authors shadowtext authors-font" style="color: #FFFFFF;font-weight: bold;font-family:DMSerifText;">
            <span class="author-block sansfont"><a href="http://tqtqliu.github.io">Tianqi Liu</a><sup>1</sup>&nbsp;&nbsp;&nbsp;</span>
            <span class="author-block sansfont"><a href="https://wanggcong.github.io">Guangcong Wang</a><sup>2,3</sup>&nbsp;&nbsp;&nbsp;</span>
            <span class="author-block sansfont"><a href="https://skhu101.github.io">Shoukang Hu</a><sup>2</sup>&nbsp;&nbsp;&nbsp;</span>
            <span class="author-block sansfont"><a href="https://leoshen917.github.io/">Liao Shen</a><sup>1</sup>&nbsp;&nbsp;&nbsp;</span>
            <span class="author-block sansfont"><a href="https://scholar.google.com/citations?user=g_Y0w7MAAAAJ&hl">Xinyi Ye</a><sup>1</sup>&nbsp;&nbsp;&nbsp;</span>
            <span class="author-block sansfont"><a href="https://yuhangzang.github.io">Yuhang Zang</a><sup>4</sup>&nbsp;&nbsp;&nbsp;</span>
            <span class="author-block sansfont"><a href="http://faculty.hust.edu.cn/caozhiguo1/en/index.htm">Zhiguo Cao</a><sup>1</sup>&nbsp;&nbsp;&nbsp;</span>
            <span class="author-block sansfont"><a href="https://weivision.github.io">Wei Li</a><sup>2</sup>&nbsp;&nbsp;&nbsp;</span>
            <span class="author-block sansfont"><a href="https://liuziwei7.github.io/">Ziwei Liu</a><sup>2</sup>&nbsp;&nbsp;&nbsp;</span>
          </div> -->
      <div class="columns is-centered" style="z-index: 1; margin-top: -80px">
            <div class="column has-text-centered ">
              <div class="publication-authors  authors-font"
                style="color: #000000;font-weight: bold;font-family:DMSerifText;">
                  <span class="author-block sansfont"><a href="http://tqtqliu.github.io">Tianqi Liu</a><sup>1</sup>&nbsp;&nbsp;&nbsp;</span>
                  <span class="author-block sansfont"><a href="https://wanggcong.github.io">Guangcong Wang</a><sup>2,3</sup>&nbsp;&nbsp;&nbsp;</span>
                  <span class="author-block sansfont"><a href="https://skhu101.github.io">Shoukang Hu</a><sup>2</sup>&nbsp;&nbsp;&nbsp;</span>
                  <span class="author-block sansfont"><a href="https://leoshen917.github.io/">Liao Shen</a><sup>1</sup>&nbsp;&nbsp;&nbsp;</span>
                  <span class="author-block sansfont"><a href="https://scholar.google.com/citations?user=g_Y0w7MAAAAJ&hl">Xinyi Ye</a><sup>1</sup>&nbsp;&nbsp;&nbsp;</span>
                  <span class="author-block sansfont"><a href="https://yuhangzang.github.io">Yuhang Zang</a><sup>4</sup>&nbsp;&nbsp;&nbsp;</span>
                  <span class="author-block sansfont"><a href="http://faculty.hust.edu.cn/caozhiguo1/en/index.htm">Zhiguo Cao</a><sup>1</sup>&nbsp;&nbsp;&nbsp;</span>
                  <span class="author-block sansfont"><a href="https://weivision.github.io">Wei Li</a><sup>2</sup>&nbsp;&nbsp;&nbsp;</span>
                  <span class="author-block sansfont"><a href="https://liuziwei7.github.io/">Ziwei Liu</a><sup>2</sup>&nbsp;&nbsp;&nbsp;</span>
              </div>

          <div class="publication-authors shadowtext authors-font" style="color: #FFFFFF;font-weight: bold;font-family:DMSerifText; margin-bottom: 4pt;">
            <span class="author-block sansfont"><sup>1</sup>Huazhong University of Science and Technology </span>
            <span class="author-block sansfont">&nbsp;&nbsp;</span>
            <span class="author-block sansfont"><sup>2</sup>Nanyang Technological University</span>
            <br />
            <span class="author-block sansfont"><sup>3</sup>Great Bay University</span>
            <span class="author-block sansfont">&nbsp;&nbsp;</span>
            <span class="author-block sansfont"><sup>4</sup>Shanghai AI Laborator</span>
          </div>

          <div class="column has-text-centered" style="font-family:DMSerifText; font-weight: bold">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/abs/2405.12218"
                  class="external-link button is-normal is-rounded light-btn btn-font">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span class="sansfont">Paper</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://youtu.be/4TxMQ9RnHMA" class="external-link button is-normal is-rounded light-btn btn-font">
                  <span class="icon">
                    <i class="fab fa-youtube"></i>
                  </span>
                  <span class="sansfont">YouTube</span>
                </a>
              </span>
  
              <span class="link-block">
                <a href="https://github.com/TQTQliu/MVSGaussian" class="external-link button is-normal is-rounded light-btn btn-font">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span class="sansfont">Code</span>
                </a>
              </span>
  
            </div>
          </div>
        </div>
      </div>
    </div>
    </div>
  </section>

<section class="section">
  <div class="container">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-two-thirds">
        <div class="content has-text-justified">
          <p>
            <strong>TL;DR:</strong> 
            MVSGaussian is a Gaussian-based method designed for efficient reconstruction of unseen scenes from sparse views in a single forward pass. 
            It offers high-quality initialization for fast training and real-time rendering.
          </p>
        </div>
        <h2 class="title is-2">Overview Video</h2>
        <div class="text-center">
              <div style="position:relative;padding-top:56.25%;">
                  <iframe width="560" height="315" src="https://www.youtube.com/embed/4TxMQ9RnHMA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
              </div>
        </div>
        <br />
        <!-- Abstract. -->
        <!-- <h2 class="title is-2">Abstract</h2> -->
        <h2 class="title is-3 sansfont mode-font" style="font-family:'Acme';color:#000000;">Abstract</h2>
        <img class="img-fluid" src="static\images\fig1.png">
        <div class="content has-text-justified">
          <p>
            We present MVSGaussian, a new generalizable 3D Gaussian representation approach derived from Multi-View Stereo (MVS) that can efficiently reconstruct unseen scenes.
            Specifically, 1) we leverage MVS to encode geometry-aware Gaussian representations and decode them into Gaussian parameters. 
            2) To further enhance performance, we propose a hybrid Gaussian rendering that integrates an efficient volume rendering design for novel view synthesis. 
            3) To support fast fine-tuning for specific scenes, we introduce a multi-view geometric consistent aggregation strategy to effectively aggregate the point clouds generated by the generalizable model, serving as the initialization for per-scene optimization. 
            Compared with previous generalizable NeRF-based methods, which typically require minutes of fine-tuning and seconds of rendering per image, MVSGaussian achieves real-time rendering with better synthesis quality for each scene. 
            Compared with the vanilla 3D-GS, MVSGaussian achieves better view synthesis with less training computational cost. 
            Extensive experiments on DTU, Real Forward-facing, NeRF Synthetic, and Tanks and Temples datasets validate that MVSGaussian attains state-of-the-art performance with convincing generalizability, real-time rendering speed, and fast per-scene optimization. 

        </div>
      </div>
    </div>
  </div>
  <!--/ Abstract. -->
</div> 

<section class="section">
  <div class="container">
  <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-two-thirds">
        <h2 class="title is-2">Method</h2>
        <img class="img-fluid" src="static\images\pipeline.png">
        <div class="content has-text-justified">
          <p>
          <b> The overview of generalizable Gaussian Splatting framework. </b> 
          MVSGaussian consists of three components: 1) <em> Depth Estimation from Multi-View Stereo. </em> The extracted multi-view features are aggregated into a cost volume, regularized by 3D CNNs to produce depth estimations. 
          2) <em> Pixel-aligned Gaussian representation. </em> Based on the obtained depth map, we encode features for each pixel-aligned 3D point.
          3) <em> Efficient hybrid Gaussian rendering. </em> We add a simple yet effective depth-aware volume rendering module to boost the generalizable performance.
        </div>
        <img class="img-fluid" src="static\images\fusion.png">
        <div class="content has-text-justified">
          <p>
          <b> Consistent aggregation. </b> 
          With depth maps and point clouds produced by the generalizable model, we conduct multi-view geometric consistency checks to derive masks for filtering out unreliable points.
          The filtered point clouds are concatenated to construct a point cloud, serving as the initialization for per-scene optimization.
        </div>
      </div>
    </div>
  </div>
  <!--/ Method. -->
</div> 





<section class="section">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-two-thirds">
        <h2 align="center"  class="title is-2">Generalization results</h2>
        <h4 align="center" class="title is-4">Qualitative comparison </h4>
        <img class="img-fluid" src="static\images\gen.png">
        <h4 align="center" class="title is-4">Video comparsion </h4>
        <div class="content has-text-justified">
        <em> Compared with generalizable NeRFs, like the state-of-the-art ENeRF, our method can achieve better performance at slightly faster speeds and with less memory overhead. </em>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 loop
                 width="100%">
            <source src="static\videos\gen.mp4"
                    type="video/mp4">
          </video>
        </div>
        <h4 align="center" class="title is-4">Depths </h4>
        <div class="content has-text-justified">
        <em> Since cost volume-based MVS explicitly models the geometry of scenes, we can obtain reasonable depth maps. </em>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                autoplay
                controls
                muted
                loop
                width="100%">
            <source src="static\videos\depths.mp4"
                    type="video/mp4">
          </video>
        </div>
        </div>
      </div>
    </div>
  </div>
</section>
    

<section class="section">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-two-thirds">
        <h2 align="center"  class="title is-2">Finetuned results</h2>
        <h4 align="center" class="title is-4">Qualitative comparison </h4>
        <img class="img-fluid" src="static\images\ft.png">
        <!-- Ours vs. ENeRF -->
        <h4 align="center" class="title is-4">Ours vs. ENeRF </h4>
        <div class="content has-text-justified">
        <em> Compared with the generalizable NeRFs, like ENeRF, our method can achieve better performance at higher rendering speeds in a shorter optimization time. </em>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 loop
                 width="100%">
            <source src="static\videos\ft_nerf.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!-- Ours vs. ENeRF -->

        <!-- Ours vs. 3D-GS -->
        <h4 align="center" style="margin-top:80px;"  class="title is-4">Ours vs. 3D-GS </h4>
        <div class="content has-text-justified">
        <em> Compared with 3D-GS, our method can achieve better performance at comparable rendering speeds in a shorter optimization time. </em
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 loop
                 width="100%">
            <source src="static\videos\ft_llff.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!-- Ours Finetuned vs. 3D-GS -->

        <!-- process -->
        <h4 align="center" style="margin-top:80px;"  class="title is-4">Optimization process</h4>
        <div class="content has-text-justified">
        <em> Due to the good initialization provided by the generalizable model, MVSGaussian requires only a short optimization time (fewer iterations) to achieve high-quality view synthesis. </em
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 loop
                 width="100%">
            <source src="static\videos\ft_process.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!-- process -->
        
      </div>
    </div>
    <!--/ Animation. -->
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @article{liu2024mvsgaussian,
          title={Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo},
          author={Liu, Tianqi and Wang, Guangcong and Hu, Shoukang and Shen, Liao and Ye, Xinyi and Zang, Yuhang and Cao, Zhiguo and Li, Wei and Liu, Ziwei},
          journal={arXiv preprint arXiv:2405.12218},
          year={2024}
      }
</code></pre>
  </div>
</section>

<section class="section">
  <div class="container">
        <h2 align="center"  class="title is-2">Related Links</h2>
        <a href="https://apchenstu.github.io/mvsnerf/">MVSNeRF:</a> Fast Generalizable Radiance Field Reconstruction from Multi-View Stereo <br>
        <a href="https://zju3dv.github.io/enerf">ENeRF</a>: Efficient Neural Radiance Fields for Interactive Free-viewpoint Video <br>
        <a href="https://ibrnet.github.io/">IBRNet:</a> Learning Multi-View Image-Based Rendering <br>
        <a href="https://gefucvpr24.github.io/">GeFu:</a> Geometry-aware Reconstruction and Fusion-refined Rendering for Generalizable Neural Radiance Fields <br>
        <a href="https://github.com/TQTQliu/ET-MVSNet">ET-MVSNet:</a> When Epipolar Constraint Meets Non-local Operators in Multi-View Stereo <br>
        <a href="https://github.com/DIVE128/DMVSNet">DMVSNet:</a> Constraining Depth Map Geometry for Multi-View Stereo: A Dual-Depth Approach with Saddle-shaped Depth Cells <br>
        <a href="https://sparsenerf.github.io/">SparseNeRF:</a> Distilling Depth Ranking for Few-shot Novel View Synthesis <br>
        <a href="https://skhu101.github.io/GauHuman/">GauHuman:</a> Articulated Gaussian Splatting from Monocular Human Videos <br>
      </div>
</section>
  

<footer class="footer">
  <div align="center" class="container">
    <div class="columns is-centered">
        <div class="content">
            This website is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
        </div>
      </div>
    </div>
</footer>
<!-- <div class="section" style="width:200px; margin-left: 40%;">  -->
  <div class="section" style="text-align:center; padding:0 0 20px 0">
    <a href="https://clustrmaps.com/site/1bzr0"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=b8aK4b3Af5vLmjWLD_399sgYOPvhr2feZkLDvFGZ1DY&cl=ffffff" /></a>
</div>

</body>
</html>
